{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ai6_KpVyFHI5",
        "outputId": "4ced48c7-0c69-47dd-dddf-5fce941b0ea0"
      },
      "outputs": [],
      "source": [
        "pip install torch torchvision torchaudio 'git+https://github.com/facebookresearch/detectron2.git' pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTr0jbbujsMx"
      },
      "outputs": [],
      "source": [
        "!apt install tesseract-ocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "dvszdgEywc4B",
        "outputId": "5c30a206-931e-460d-ee12-48d80d2d189f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "# Detectron2 config\n",
        "cfg = get_cfg()\n",
        "cfg = model_zoo.get_config(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.1\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "def align_document(image, mask):\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    contour = max(contours, key=cv2.contourArea)\n",
        "    rect = cv2.minAreaRect(contour)\n",
        "    box = cv2.boxPoints(rect)\n",
        "    box = np.int0(box)\n",
        "\n",
        "    center = np.mean(box, axis=0)\n",
        "    corners = sorted(box, key=lambda corner: np.arctan2(corner[1] - center[1], corner[0] - center[0]))\n",
        "\n",
        "    width = int(max(np.linalg.norm(corners[0] - corners[1]), np.linalg.norm(corners[2] - corners[3])))\n",
        "    height = int(max(np.linalg.norm(corners[1] - corners[2]), np.linalg.norm(corners[3] - corners[0])))\n",
        "    aligned_corners = np.float32([[0, 0], [width, 0], [width, height], [0, height]])\n",
        "\n",
        "    M = cv2.getPerspectiveTransform(np.float32(corners), aligned_corners)\n",
        "\n",
        "    aligned_image = cv2.warpPerspective(image, M, (width, height))\n",
        "\n",
        "    return aligned_image\n",
        "\n",
        "def rotate_image_if_needed(image):\n",
        "    height, width = image.shape[:2]\n",
        "    if height > width:\n",
        "        image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
        "    return image\n",
        "\n",
        "def get_card(image):\n",
        "    result = []\n",
        "    outputs = predictor(image)\n",
        "    instances = outputs[\"instances\"].to(\"cpu\")\n",
        "    classes = instances.pred_classes\n",
        "    boxes = instances.pred_boxes.tensor.numpy()\n",
        "    masks = instances.pred_masks.numpy()\n",
        "    book_class_index = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes.index('book')\n",
        "    book_indices = np.where(classes == book_class_index)[0]\n",
        "\n",
        "    if len(book_indices) > 0:\n",
        "        book_boxes = boxes[book_indices]\n",
        "        book_masks = masks[book_indices]\n",
        "\n",
        "        for box, mask in zip(book_boxes, book_masks):\n",
        "            x1, y1, x2, y2 = box.astype(int)\n",
        "            mask = (mask[y1:y2, x1:x2] * 255).astype(np.uint8)\n",
        "            aligned_image = align_document(image[y1:y2, x1:x2], mask)\n",
        "            result.append(rotate_image_if_needed(aligned_image))\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "rdEaqIT-iC05"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "color_white = (255, 255, 255)\n",
        "\n",
        "rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (13, 5))\n",
        "sqKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (21, 21))\n",
        "\n",
        "\n",
        "def smooth_image(gray):\n",
        "    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "    return cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, rectKernel)\n",
        "\n",
        "\n",
        "# https://pythongeeks.org/sobel-and-scharr-operator-in-opencv/\n",
        "def compute_gradient(black_hat):\n",
        "    gradX = cv2.Sobel(black_hat, ddepth=cv2.CV_32F, dx=1, dy=0, ksize=-1)\n",
        "    gradX = np.absolute(gradX)\n",
        "    (minVal, maxVal) = (np.min(gradX), np.max(gradX))\n",
        "    return (255 * ((gradX - minVal) / (maxVal - minVal))).astype(\"uint8\")\n",
        "\n",
        "\n",
        "# Размываем текст чтобы слепить его в единный камок\n",
        "def apply_closing_operations(gradX, rectKernel, sqKernel):\n",
        "    gradX = cv2.morphologyEx(gradX, cv2.MORPH_CLOSE, rectKernel)\n",
        "    thresh = cv2.threshold(gradX, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
        "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, sqKernel)\n",
        "    return cv2.erode(thresh, None, iterations=4)\n",
        "\n",
        "\n",
        "# При размытие мы могли соъединить текст с границами, убераем 5% слева и справа\n",
        "def remove_border_pixels(thresh, image):\n",
        "    p = int(image.shape[1] * 0.05)\n",
        "    thresh[:, 0:p] = 0\n",
        "    thresh[:, image.shape[1] - p:] = 0\n",
        "    return thresh\n",
        "\n",
        "\n",
        "def find_contours(thresh):\n",
        "    contours = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
        "                                cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
        "    return sorted(contours, key=cv2.contourArea, reverse=True)\n",
        "\n",
        "\n",
        "def resize_image(img, height):\n",
        "    width = int(img.shape[1] * height / img.shape[0])\n",
        "    return cv2.resize(img, (width, height))\n",
        "\n",
        "\n",
        "def get_mrz_image(img):\n",
        "    image = resize_image(img, 600)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    black_hat = smooth_image(gray)\n",
        "    gradX = compute_gradient(black_hat)\n",
        "    thresh = apply_closing_operations(gradX, rectKernel, sqKernel)\n",
        "    thresh = remove_border_pixels(thresh, image)\n",
        "    contours = find_contours(thresh)\n",
        "    return extract_roi(contours, gray, image)\n",
        "\n",
        "\n",
        "def extract_roi(contours, gray, image):\n",
        "    for c in contours:\n",
        "        (x, y, w, h) = cv2.boundingRect(c)\n",
        "        ar = w / float(h)\n",
        "        crWidth = w / float(gray.shape[1])\n",
        "\n",
        "        if ar > 5 and crWidth > 0.75:\n",
        "            pX = int((x + w) * 0.03)\n",
        "            pY = int((y + h) * 0.03)\n",
        "            (x, y) = (x - pX, y - pY)\n",
        "            (w, h) = (w + (pX * 2), h + (pY * 2))\n",
        "\n",
        "            roi = image[y:y + h, x:x + w].copy()\n",
        "            break\n",
        "\n",
        "    return roi\n",
        "\n",
        "\n",
        "def rotate_image(mat, angle):\n",
        "    height, width = mat.shape[:2]\n",
        "    image_center = (\n",
        "        width / 2,\n",
        "        height / 2)\n",
        "\n",
        "    rotation_mat = cv2.getRotationMatrix2D(image_center, angle, 1.)\n",
        "\n",
        "    abs_cos = abs(rotation_mat[0, 0])\n",
        "    abs_sin = abs(rotation_mat[0, 1])\n",
        "\n",
        "    bound_w = int(height * abs_sin + width * abs_cos)\n",
        "    bound_h = int(height * abs_cos + width * abs_sin)\n",
        "\n",
        "    rotation_mat[0, 2] += bound_w / 2 - image_center[0]\n",
        "    rotation_mat[1, 2] += bound_h / 2 - image_center[1]\n",
        "\n",
        "    rotated_mat = cv2.warpAffine(mat, rotation_mat,\n",
        "                                (bound_w, bound_h),\n",
        "                                 borderMode=cv2.BORDER_CONSTANT,\n",
        "                                 borderValue=color_white,\n",
        "                                 )\n",
        "    return rotated_mat\n",
        "\n",
        "\n",
        "def convert_to_binary(img):\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.GaussianBlur(img, (5, 5), 225)\n",
        "    se = cv2.getStructuringElement(cv2.MORPH_RECT, (8, 8))\n",
        "    bg = cv2.morphologyEx(img, cv2.MORPH_DILATE, se)\n",
        "    out_gray = cv2.divide(img, bg, scale=255)\n",
        "    out_binary = cv2.threshold(out_gray, 0, 255, cv2.THRESH_OTSU)[1]\n",
        "    return out_binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "gT7yBMqGidAX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pytesseract import pytesseract\n",
        "os.environ['TESSDATA_PREFIX'] = '/content/tesseract_data'\n",
        "\n",
        "class Back:\n",
        "    def __init__(self, img):\n",
        "        self._image = img\n",
        "        self.set_MRZ_image()\n",
        "        self.set_MRZ()\n",
        "\n",
        "    def set_MRZ_image(self):\n",
        "        self._MRZ_image = convert_to_binary(get_mrz_image(self._image))\n",
        "\n",
        "    # https://github.com/DoubangoTelecom/tesseractMRZ/\n",
        "    def set_MRZ(self):\n",
        "        self.MRZ = pytesseract.image_to_string(self._MRZ_image, lang='mrz', config='--psm 6')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "tKfDd-N_sTiH"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def validate_mrz(mrz: str) -> bool:\n",
        "    pattern = r'([A-Z0-9<]{30}\\n?){3}'\n",
        "    return bool(re.match(pattern, mrz))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wpey28BBJrl",
        "outputId": "0d6310d8-6a57-4edf-8d3e-18eeb3463040"
      },
      "outputs": [],
      "source": [
        "def helper(img) -> str:\n",
        "  try:\n",
        "      passport = Back(img)\n",
        "      return passport.MRZ\n",
        "  except UnboundLocalError:\n",
        "      return 'bad image'\n",
        "\n",
        "img = cv2.imread('/content/data_set/1.jpg')\n",
        "images = get_card(img)\n",
        "mrz = []\n",
        "for image in images:\n",
        "  m = helper(image)\n",
        "  if validate_mrz(m):\n",
        "    mrz.append(m)\n",
        "\n",
        "  m = helper(rotate_image(image, 180))\n",
        "  if validate_mrz(m):\n",
        "    mrz.append(m)\n",
        "\n",
        "if len(mrz) == 0:\n",
        "  print(\"не удалось корректно обработать изображение\")\n",
        "else:\n",
        "  print(mrz[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "cell_execution_strategy": "setup",
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
